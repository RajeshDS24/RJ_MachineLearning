Test_pca <- predict(PCA_Res, Test_set)
Test_pca <- data.frame(Test_pca, Test_set[1])
PCA_RF_Model <- randomForest(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, ntree=500, proximity=T, importance=T)
PCA_RF_predict <- predict(PCA_RF_Model, Test_pca[,-31])
PCA_RF_CM    <- confusionMatrix(PCA_RF_predict, Test_pca$diagnosis)
PCA_RF_CM
# 92.94
# plot the RAndom Forest Error vs Trees after Correlation Feature Selection.
plot(PCA_RF_Model, main= "Error Rate Vs Number of Tree Of Random Forest Model")
PCA_RF_Model <- randomForest(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, ntree=500, proximity=T, importance=T)
PCA_RF_predict <- predict(PCA_RF_Model, Test_pca[,-31])
PCA_RF_CM    <- confusionMatrix(PCA_RF_predict, Test_pca$diagnosis)
PCA_RF_CM
set.seed(145)
#  PCA Training and testing data
Train_pca <- predict(PCA_Res, Train_set)
Train_pca <- data.frame(Train_pca, Train_set[1])
Test_pca <- predict(PCA_Res, Test_set)
Test_pca <- data.frame(Test_pca, Test_set[1])
#  PCA Training and testing data
Train_pca <- predict(PCA_Res, Train_set)
Train_pca <- data.frame(Train_pca, Train_set[1])
Test_pca <- predict(PCA_Res, Test_set)
Test_pca <- data.frame(Test_pca, Test_set[1])
## Model 1
## Logistic Regression using PCA
LR_with_PCA <- train(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, method = "glm")
LR_Pred_PCA <- predict(LR_with_PCA, Test_pca)
con.mat_LR <- confusionMatrix(LR_Pred_PCA, Test_pca$diagnosis, positive = "M")
con.mat_LR
## 97.06%
# Model 2
## Neural Networks using PCA
NN_PCA <- nnet(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, size = 10, linout = FALSE )
# Plot the N
plotnet(NN_PCA)
# Predict
NN_Predict_PCA <-  predict(NN_PCA, Test_pca[,-31 ], type = c('class'))
# Predict.results
Acc_NN_PCA <- sum(Test_pca$diagnosis == NN_Predict_PCA)/nrow(Test_pca)
Acc_NN_PCA
# 95.29
# Model 3
# Decision Tree using PCA features.
DT_Model_PCA <- rpart(diagnosis~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, control=rpart.control(minsplit=2))
DT_predict_PCA <- predict(DT_Model_PCA, Test_pca[ ,-31], type="class")
DT_CM_PCA  <- confusionMatrix(DT_predict_PCA, Test_pca$diagnosis)
DT_CM_PCA # 92.35
# pruning the DT
CP_Value_PCA <- DT_Model_PCA$cptable[which.min(DT_Model_PCA$cptable[,"xerror"]),"CP"]
DT_Model_PCA_Prune <- prune(DT_Model_PCA, cp = CP_Value_PCA)
DT_predict_PCA_prune <- predict(DT_Model_PCA_Prune, Test_pca[ ,-31], type="class")
PCA_DT_CM_Prune <-confusionMatrix(DT_predict_PCA_prune, Test_pca$diagnosis)
PCA_DT_CM_Prune  # 92.35
# Model 4
PCA_RF_Model <- randomForest(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, ntree=500, proximity=T, importance=T)
PCA_RF_predict <- predict(PCA_RF_Model, Test_pca[,-31])
PCA_RF_CM    <- confusionMatrix(PCA_RF_predict, Test_pca$diagnosis)
PCA_RF_CM
# 92.94
# plot the RAndom Forest Error vs Trees after Correlation Feature Selection.
plot(PCA_RF_Model, main= "Error Rate Vs Number of Tree Of Random Forest Model")
## visualizing cancer data.
# View the proportion of the classes in Diagnosis
ggplot(cancer_data, aes(x = factor(diagnosis), fill = diagnosis )) +
labs(title = "Distribution of Observations in the dataset.", x = "Diagnosis", y = "Number of observations" ) +
geom_bar(color = "black") + scale_fill_brewer(palette = "Paired")
varImp(PCA_RF_Model)
ggcorr(cancer_data[,c(-1)], name = "corr", label = TRUE) +
theme(legend.position="none") +
labs(title="Cancer Mean Data")+
theme(plot.title = element_text(face='bold',color='black',hjust=0.5,size=12))
cancer_data[ ,c(-1)]
colnames(cancer_data)
ggcorr(cancer_data[ , c(-1)], name = "corr", label = T)
ggcorr(cancer_data[ , c(-1)],  label = T)
ggcorr(cancer_data[ , c(-1)], name = "corr")
remove.packages("GGally")
install.packages("GGally")
library(GGally)
install.packages("GGally")
library(GGally)
library(ggplot2)
library(dplyr)
library(caret)
library(nnet)
library(NeuralNetTools)
library(RColorBrewer)
library(corrplot)
# get data
Raw_cancer_data <- read.csv("data.csv")
# Removing the unwanted columns
cancer_data <- Raw_cancer_data[c(-1,-33)]
## visualizing cancer data.
# View the proportion of the classes in Diagnosis
ggplot(cancer_data, aes(x = factor(diagnosis), fill = diagnosis )) +
labs(title = "Distribution of Observations in the dataset.", x = "Diagnosis", y = "Number of observations" ) +
geom_bar(color = "black") + scale_fill_brewer(palette = "Paired")
mean_data <- round(cancer_data[,c(2:11)], 2)
colnames(mean_data)
SD_data <- round(cancer_data[,c(12:21)], 2)
colnames(SD_data)
Worst_data <- round(cancer_data[,c(22:31)], 2)
ggcorr(cancer_data[ ,c(-1)], name = "corr", label = TRUE) +
theme(legend.position="none") +
labs(title="Cancer Mean Data")+
theme(plot.title = element_text(face='bold',color='black',hjust=0.5,size=12))
ggcorr(SD_data, name = "corr", label = TRUE)
Raw_cancer_data <- read.csv("data.csv")
cancer_data <- Raw_cancer_data[c(-1,-33)]
colnames(cancer_data)
mean_data <- round(cancer_data[,c(2:11)], 2)
colnames(mean_data)
SD_data <- round(cancer_data[,c(12:21)], 2)
colnames(SD_data)
Worst_data <- round(cancer_data[,c(22:31)], 2)
colnames(Worst_data)
cancer_data[,c(1)]
ggcorr(cancer_data[,c(-1)], name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Mean")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
ggcorr(cancer_data[,c(-1)], name = "corr", label = TRUE, na_value = "transparent") +
theme(legend.position="none")+
labs(title="Cancer Mean")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
ggcorr(mean_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Mean")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
install.packages("farver")
install.packages("farver")
library(farver)
ggcorr(mean_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Mean")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
ggcorr(cancer_data[ ,c(-1)], name = "corr", label = TRUE) +
theme(legend.position="none") +
labs(title="Cancer Mean Data")+
theme(plot.title = element_text(face='bold',color='black',hjust=0.5,size=12))
## Correlation for Mean data
ggcorr(mean_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Mean Data")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
## Correlation for SE data
ggcorr(SD_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Mean Data")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
## Correlation for worst data
ggcorr(Worst_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Mean Data")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
filter_data <- cancer_data[, -high_Corr_data]
dim(filter_data)
filter_data
library(ggplot2)
library(dplyr)
library(caret)
library(nnet)
library(NeuralNetTools)
library(RColorBrewer)
library(corrplot)
library(GGally)
library(farver)
# get data
Raw_cancer_data <- read.csv("data.csv")
# get data
Raw_cancer_data <- read.csv("data.csv")
# Removing the unwanted columns
cancer_data <- Raw_cancer_data[c(-1,-33)]
## visualizing cancer data.
# View the proportion of the classes in Diagnosis
ggplot(cancer_data, aes(x = factor(diagnosis), fill = diagnosis )) +
labs(title = "Distribution of Observations in the dataset.", x = "Diagnosis", y = "Number of observations" ) +
geom_bar(color = "black") + scale_fill_brewer(palette = "Paired")
mean_data <- round(cancer_data[,c(2:11)], 2)
SD_data <- round(cancer_data[,c(12:21)], 2)
Worst_data <- round(cancer_data[,c(22:31)], 2)
ggcorr(cancer_data[ ,c(-1)], name = "corr", label = TRUE) +
theme(legend.position="none") +
labs(title="Cancer Mean Data")+
theme(plot.title = element_text(face='bold',color='black',hjust=0.5,size=12))
## Correlation for Mean data
ggcorr(mean_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Mean Data")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
## Correlation for SE data
ggcorr(SD_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Mean Data")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
## Correlation for worst data
ggcorr(Worst_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Mean Data")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
## Train and test data:
set.seed(165)
# from caret package
sample_set <- createDataPartition(cancer_data$diagnosis, times = 1, p = 0.7, list = F)
# Training set
Train_set <- cancer_data[sample_set,]
# Testing set
Test_set <- cancer_data[-sample_set, ]
model_LR <- train(diagnosis~., data = Train_set, method = "glm")
Pred_LR <- predict(model_LR, Test_set)
con.mat_LR <- confusionMatrix(Pred_LR, Test_set$diagnosis, positive = "M")
con.mat_LR
# Neural Networks
NN_Model1 <- nnet(Train_set$diagnosis~., data = Train_set, size = 10, linout = FALSE )
# Plot the N
plotnet(NN_Model1)
# Predict
Predict.results <-  predict(NN_Model1, Test_set[, -1], type = c('class'))
acc <- sum(Test_set$diagnosis == Predict.results)/nrow(Test_set)
acc
# Decision Tree
library(rpart)
DT_Model <- rpart(diagnosis~., data=Train_set, control=rpart.control(minsplit=2))
DT_predict <- predict(DT_Model, Test_set[,-1], type="class")
DT_CM  <- confusionMatrix(DT_predict, Test_set$diagnosis)
DT_CM # 91.18
# pruning the DT
CP_Value <- DT_Model$cptable[which.min(DT_Model$cptable[,"xerror"]),"CP"]
DT_Model_Prune <- prune(DT_Model, cp = CP_Value)
DT_predict_prune <- predict(DT_Model_Prune, Test_set[,-1], type="class")
DT_CM_Prune <-confusionMatrix(DT_predict_prune, Test_set$diagnosis)
DT_CM_Prune # 91.76
library(randomForest)
RF_Model <- randomForest(diagnosis ~., data=Train_set, ntree=500, proximity=T, importance=T)
RF_predict <- predict(RF_Model, Test_set[,-1])
RF_CM    <- confusionMatrix(RF_predict, Test_set$diagnosis)
RF_CM
# plot the RAndom Forest Error vs Trees.
plot(RF_Model, main= "Error Rate Vs Number of Tree Of Random Forest Model")
# Finding Correlation between the independent variables
Cor_data <- cor(cancer_data[,c(-1)])
# Highly Correlated data.
high_Corr_data <- findCorrelation(Cor_data, cutoff = .85)
filter_data <- cancer_data[, -high_Corr_data]
dim(filter_data)
filter_data$diagnosis <- cbind(as.character(cancer_data$diagnosis))
filter_data$diagnosis <- as.factor(filter_data$diagnosis)
class(filter_data$diagnosis)
# Partitioning the data
FS1_set <- createDataPartition(filter_data$diagnosis, times = 1, p = 0.7, list = F)
# New Training set
Train1_set <- filter_data[FS1_set,]
# New Testing set
Test1_set <- filter_data[-FS1_set, ]
CR_LR.model <- train(diagnosis ~., data = Train1_set, method = "glm")
CR_Pred_LR <- predict(CR_LR.model, Test1_set)
CR_con.mat_LR <- confusionMatrix(CR_Pred_LR, Test1_set$diagnosis, positive = "M")
CR_con.mat_LR
set.seed(101)
# Partitioning the data
FS1_set <- createDataPartition(filter_data$diagnosis, times = 1, p = 0.7, list = F)
# New Training set
Train1_set <- filter_data[FS1_set,]
# New Testing set
Test1_set <- filter_data[-FS1_set, ]
set.seed(101)
CR_LR.model <- train(diagnosis ~., data = Train1_set, method = "glm")
CR_Pred_LR <- predict(CR_LR.model, Test1_set)
CR_con.mat_LR <- confusionMatrix(CR_Pred_LR, Test1_set$diagnosis, positive = "M")
CR_con.mat_LR
# Neural Networks
CR_NN_Model1 <- nnet(Train1_set$diagnosis~., data = Train1_set, size = 10, linout = FALSE )
# Neural Networks
CR_NN_Model1 <- nnet(Train1_set$diagnosis~., data = Train1_set, size = 10, linout = FALSE )
# Plot the N
plotnet(CR_NN_Model1)
CR_Predict.results <-  predict(CR_NN_Model1, Test1_set[, -19], type = c('class'))
CR_acc <- sum(Test1_set$diagnosis == CR_Predict.results)/nrow(Test1_set)
CR_acc
CR_DT_Model <- rpart(diagnosis~., data = Train1_set, control=rpart.control(minsplit=2))
CR_DT_predict <- predict(CR_DT_Model, Test1_set[,-19], type="class")
CR_DT_CM  <- confusionMatrix(CR_DT_predict, Test1_set$diagnosis)
CR_DT_CM # 93.53
# pruning the DT
CP_Value_CR <- CR_DT_Model$cptable[which.min(CR_DT_Model$cptable[,"xerror"]),"CP"]
DT_Model_Prune <- prune(CR_DT_Model, cp = CP_Value_CR)
DT_predict_prune <- predict(DT_Model_Prune, Test1_set[,-19], type="class")
CR_DT_CM_Prune <-confusionMatrix(DT_predict_prune, Test1_set$diagnosis)
CR_DT_CM_Prune # 94.12
CR_RF_Model <- randomForest(diagnosis ~., data = Train1_set, ntree=500, proximity=T, importance=T)
CR_RF_predict <- predict(CR_RF_Model, Test1_set[,-19])
CR_RF_CM    <- confusionMatrix(CR_RF_predict, Test1_set$diagnosis)
CR_RF_CM
# plot the RAndom Forest Error vs Trees after Correlation Feature Selection.
plot(CR_RF_Model, main= "Error Rate Vs Number of Tree Of Random Forest Model")
# PCA calculation
PCA_Res <- prcomp(cancer_data[,2:ncol(cancer_data)], center = TRUE, scale = TRUE)
# plot the variances
plot(PCA_Res, type="l", main = " Variance by Components Explanation")
library(factoextra)
## Screen Plot
fviz_eig(PCA_Res, addlabels=TRUE, ylim=c(0,60), geom = c("bar", "line"), barfill = "pink", barcolor="grey",linecolor = "red", ncp=10)+
labs(title = "PCA variance captured",
x = "Principal Components", y = "% of variances")
# Collect the variables from PCA
Collect_var <- get_pca_var(PCA_Res)
Collect_var
# plot the correlation between the variables and PCA
library("corrplot")
corrplot(Collect_var$cos2, is.corr=FALSE)
# To get the mostly contributed variables to the Principle components
corrplot(Collect_var$contrib, is.corr=FALSE)
# To check the cumulative proportion - the variance captured by the Principle Complonents.
summary(PCA_Res)
# BiPlot
fviz_pca_biplot(PCA_Res, col.ind = cancer_data$diagnosis, col="black",
palette = "jco", geom = "point", repel=TRUE,
legend.title="Diagnosis", addEllipses = TRUE)
set.seed(145)
#  PCA Training and testing data
Train_pca <- predict(PCA_Res, Train_set)
Train_pca <- data.frame(Train_pca, Train_set[1])
Test_pca <- predict(PCA_Res, Test_set)
Test_pca <- data.frame(Test_pca, Test_set[1])
LR_with_PCA <- train(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, method = "glm")
LR_Pred_PCA <- predict(LR_with_PCA, Test_pca)
con.mat_LR <- confusionMatrix(LR_Pred_PCA, Test_pca$diagnosis, positive = "M")
con.mat_LR
#  PCA Training and testing data
Train_pca <- predict(PCA_Res, Train_set)
Train_pca <- data.frame(Train_pca, Train_set[1])
Test_pca <- predict(PCA_Res, Test_set)
Test_pca <- data.frame(Test_pca, Test_set[1])
LR_with_PCA <- train(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, method = "glm")
LR_Pred_PCA <- predict(LR_with_PCA, Test_pca)
con.mat_LR <- confusionMatrix(LR_Pred_PCA, Test_pca$diagnosis, positive = "M")
con.mat_LR
set.seed(145)
#  PCA Training and testing data
Train_pca <- predict(PCA_Res, Train_set)
Train_pca <- data.frame(Train_pca, Train_set[1])
Test_pca <- predict(PCA_Res, Test_set)
Test_pca <- data.frame(Test_pca, Test_set[1])
LR_with_PCA <- train(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, method = "glm")
LR_Pred_PCA <- predict(LR_with_PCA, Test_pca)
con.mat_LR <- confusionMatrix(LR_Pred_PCA, Test_pca$diagnosis, positive = "M")
con.mat_LR
set.seed(144)
#  PCA Training and testing data
Train_pca <- predict(PCA_Res, Train_set)
Train_pca <- data.frame(Train_pca, Train_set[1])
Test_pca <- predict(PCA_Res, Test_set)
Test_pca <- data.frame(Test_pca, Test_set[1])
LR_with_PCA <- train(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, method = "glm")
LR_Pred_PCA <- predict(LR_with_PCA, Test_pca)
con.mat_LR <- confusionMatrix(LR_Pred_PCA, Test_pca$diagnosis, positive = "M")
con.mat_LR
set.seed(101)
#  PCA Training and testing data
Train_pca <- predict(PCA_Res, Train_set)
Train_pca <- data.frame(Train_pca, Train_set[1])
Test_pca <- predict(PCA_Res, Test_set)
Test_pca <- data.frame(Test_pca, Test_set[1])
LR_with_PCA <- train(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, method = "glm")
LR_Pred_PCA <- predict(LR_with_PCA, Test_pca)
con.mat_LR <- confusionMatrix(LR_Pred_PCA, Test_pca$diagnosis, positive = "M")
con.mat_LR
# Model 2
## Neural Networks using PCA
NN_PCA <- nnet(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, size = 10, linout = FALSE )
set.seed(111)
#  PCA Training and testing data
Train_pca <- predict(PCA_Res, Train_set)
Train_pca <- data.frame(Train_pca, Train_set[1])
Test_pca <- predict(PCA_Res, Test_set)
Test_pca <- data.frame(Test_pca, Test_set[1])
LR_with_PCA <- train(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, method = "glm")
LR_Pred_PCA <- predict(LR_with_PCA, Test_pca)
con.mat_LR <- confusionMatrix(LR_Pred_PCA, Test_pca$diagnosis, positive = "M")
con.mat_LR
# PCA calculation
PCA_Res <- prcomp(cancer_data[,2:ncol(cancer_data)], center = TRUE, scale = TRUE)
# plot the variances
plot(PCA_Res, type="l", main = " Variance by Components Explanation")
install.packages("factoextra")
library(factoextra)
## Screen Plot
fviz_eig(PCA_Res, addlabels=TRUE, ylim=c(0,60), geom = c("bar", "line"), barfill = "pink", barcolor="grey",linecolor = "red", ncp=10)+
labs(title = "PCA variance captured",
x = "Principal Components", y = "% of variances")
# Collect the variables from PCA
Collect_var <- get_pca_var(PCA_Res)
Collect_var
# plot the correlation between the variables and PCA
library("corrplot")
corrplot(Collect_var$cos2, is.corr=FALSE)
# To get the mostly contributed variables to the Principle components
corrplot(Collect_var$contrib, is.corr=FALSE)
# To check the cumulative proportion - the variance captured by the Principle Complonents.
summary(PCA_Res)
# BiPlot
fviz_pca_biplot(PCA_Res, col.ind = cancer_data$diagnosis, col="black",
palette = "jco", geom = "point", repel=TRUE,
legend.title="Diagnosis", addEllipses = TRUE)
set.seed(111)
#  PCA Training and testing data
Train_pca <- predict(PCA_Res, Train_set)
Train_pca <- data.frame(Train_pca, Train_set[1])
Test_pca <- predict(PCA_Res, Test_set)
Test_pca <- data.frame(Test_pca, Test_set[1])
LR_with_PCA <- train(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, method = "glm")
LR_Pred_PCA <- predict(LR_with_PCA, Test_pca)
con.mat_LR <- confusionMatrix(LR_Pred_PCA, Test_pca$diagnosis, positive = "M")
con.mat_LR
# Model 2
## Neural Networks using PCA
NN_PCA <- nnet(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, size = 10, linout = FALSE )
# Model 2
## Neural Networks using PCA
NN_PCA <- nnet(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, size = 10, linout = FALSE )
# Plot the N
plotnet(NN_PCA)
# Predict
NN_Predict_PCA <-  predict(NN_PCA, Test_pca[,-31 ], type = c('class'))
Acc_NN_PCA <- sum(Test_pca$diagnosis == NN_Predict_PCA)/nrow(Test_pca)
Acc_NN_PCA
# Model 2
## Neural Networks using PCA
NN_PCA <- nnet(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, size = 8, linout = FALSE )
# Plot the N
plotnet(NN_PCA)
# Predict
NN_Predict_PCA <-  predict(NN_PCA, Test_pca[,-31 ], type = c('class'))
Acc_NN_PCA <- sum(Test_pca$diagnosis == NN_Predict_PCA)/nrow(Test_pca)
Acc_NN_PCA
DT_Model_PCA <- rpart(diagnosis~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, control=rpart.control(minsplit=2))
DT_predict_PCA <- predict(DT_Model_PCA, Test_pca[ ,-31], type="class")
DT_CM_PCA  <- confusionMatrix(DT_predict_PCA, Test_pca$diagnosis)
DT_CM_PCA # 92.35
# pruning the DT
CP_Value_PCA <- DT_Model_PCA$cptable[which.min(DT_Model_PCA$cptable[,"xerror"]),"CP"]
DT_Model_PCA_Prune <- prune(DT_Model_PCA, cp = CP_Value_PCA)
DT_predict_PCA_prune <- predict(DT_Model_PCA_Prune, Test_pca[ ,-31], type="class")
PCA_DT_CM_Prune <-confusionMatrix(DT_predict_PCA_prune, Test_pca$diagnosis)
PCA_DT_CM_Prune  # 92.35
# Model 4
PCA_RF_Model <- randomForest(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = Train_pca, ntree=500, proximity=T, importance=T)
PCA_RF_predict <- predict(PCA_RF_Model, Test_pca[,-31])
PCA_RF_CM    <- confusionMatrix(PCA_RF_predict, Test_pca$diagnosis)
PCA_RF_CM
# 92.94
# plot the RAndom Forest Error vs Trees after Correlation Feature Selection.
plot(PCA_RF_Model, main = "Error Rate Vs Number of Tree Of Random Forest Model")
colnames(filter_data)
## visualizing cancer data.
# View the proportion of the classes in Diagnosis
ggplot(cancer_data, aes(x = factor(diagnosis), fill = diagnosis )) +
labs(title = "Distribution of Observations in the dataset.", x = "Diagnosis", y = "Number of observations" ) +
geom_bar(color = "black") + scale_fill_brewer(palette = "Paired")
ggcorr(cancer_data[ ,c(-1)], name = "corr", label = TRUE) +
theme(legend.position="none") +
labs(title="Cancer Mean Data")+
theme(plot.title = element_text(face='bold',color='black',hjust=0.5,size=12))
## Correlation for Mean data
ggcorr(mean_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Mean Data")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
## Correlation for SE data
ggcorr(SD_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Mean Data")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
ggcorr(cancer_data[ ,c(-1)], name = "corr", label = TRUE) +
theme(legend.position="none") +
labs(title="Cancer Data")+
theme(plot.title = element_text(face='bold',color='black',hjust=0.5,size=12))
## Correlation for Mean data
ggcorr(mean_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Mean Data")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
## Correlation for SE data
ggcorr(SD_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer SE Data")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
## Correlation for worst data
ggcorr(Worst_data, name = "corr", label = TRUE) +
theme(legend.position="none")+
labs(title="Cancer Worst Data")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
# plot the RAndom Forest Error vs Trees.
plot(RF_Model, main= "Error Rate Vs Number of Tree Of Random Forest Model")
# plot the RAndom Forest Error vs Trees after Correlation Feature Selection.
plot(CR_RF_Model, main= "Error Rate Vs Number of Tree Of Random Forest Model")
# plot the variances
plot(PCA_Res, type="l", main = " Variance by Components Explanation")
## Screen Plot
fviz_eig(PCA_Res, addlabels=TRUE, ylim=c(0,60), geom = c("bar", "line"), barfill = "pink", barcolor="grey",linecolor = "red", ncp=10)+
labs(title = "PCA variance captured",
x = "Principal Components", y = "% of variances")
corrplot(Collect_var$cos2, is.corr=FALSE)
# To get the mostly contributed variables to the Principle components
corrplot(Collect_var$contrib, is.corr=FALSE)
# BiPlot
fviz_pca_biplot(PCA_Res, col.ind = cancer_data$diagnosis, col="black",
palette = "jco", geom = "point", repel=TRUE,
legend.title="Diagnosis", addEllipses = TRUE)
# plot the RAndom Forest Error vs Trees after Correlation Feature Selection.
plot(PCA_RF_Model, main = "Error Rate Vs Number of Tree Of Random Forest Model")
